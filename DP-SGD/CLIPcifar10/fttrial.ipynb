{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7239,"status":"ok","timestamp":1701792207311,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"},"user_tz":300},"id":"MchLWDeuIFIq","outputId":"59a85f21-5c03-45ae-c3e5-1a2409c5e2c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/awslabs/fast-differential-privacy\n","  Cloning https://github.com/awslabs/fast-differential-privacy to /tmp/pip-req-build-klvthkbe\n","  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy /tmp/pip-req-build-klvthkbe\n","  Resolved https://github.com/awslabs/fast-differential-privacy to commit 1202baa441c38c338415bc24e4cf12514c46bac0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastDP\n","  Building wheel for fastDP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastDP: filename=fastDP-1.1.0-py3-none-any.whl size=101664 sha256=63c818dd9defd00dd3b8acd190b70791dad741f479ec253d79a1b87af07c7184\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-znajak9f/wheels/b3/2b/b5/62668a08336b29e28ca790358738474aa8c2c68359b494f454\n","Successfully built fastDP\n","Installing collected packages: fastDP\n","Successfully installed fastDP-1.1.0\n"]}],"source":["%pip install git+https://github.com/awslabs/fast-differential-privacy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21365,"status":"ok","timestamp":1701792228669,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"},"user_tz":300},"id":"nt1HGG1z-9-y","outputId":"c16ee287-282c-4d87-b9ba-7d3e67aaf929"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/Othercomputers/My Mac/CLIPcifar10/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeQ-nTlrp3NJ","executionInfo":{"status":"ok","timestamp":1701792228669,"user_tz":300,"elapsed":6,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"495cd18b-efb6-4ffe-e4ef-1a19bf6256eb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Mac/CLIPcifar10\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oFfio93KO12","outputId":"d0c41caf-6169-472c-9437-83cbd4457168"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","Accuracy of the network on the 10000 test images: 10 %\n","Accuracy of the network on the 10000 test images: 10 %\n","Accuracy of the network on the 10000 test images: 10 %\n","Accuracy of the network on the 10000 test images: 10 %\n","Accuracy of the network on the 10000 test images: 10 %\n"]}],"source":["!python finetuning.py --name fttrial --seed 0 --epoch 20 --epsilon 1 --b 100 --lr 0.1"]},{"cell_type":"markdown","source":["### s0e50eps1.5b100lr0.001 Adam result\n","\n","10 %\n",",10 %\n",",10 %\n",",10 %\n",",10 %\n",",9 %\n",",11 %\n",",9 %\n","\n","### s0e50eps1.5b100lr0.001 SGD result\n","\n","9 %\n",",10 %\n",",10 %\n",",11 %\n",",12 %\n",",13 %\n",",15 %\n",",17 %\n","\n","### s0e50eps1.5b100lr0.01 SGD result\n","\n","15 %\n",",27 %\n",",36 %\n",",38 %\n",",37 %\n",",36 %\n",",35 %\n",",34 %\n",",34 %\n",",34 %\n",",34 %\n",",33 %\n","\n","### s0e20eps1b100lr0.1 SGD result\n","\n","10 %,10 %,10 %,10 %,10 %"],"metadata":{"id":"glSqn5O_Jdc1"}}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPHnYLDIbHNqj4rmGfLCTuV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}