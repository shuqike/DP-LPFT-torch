{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7879,"status":"ok","timestamp":1701802876664,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"},"user_tz":300},"id":"MchLWDeuIFIq","outputId":"5fc361be-b410-46b4-f646-f4dae7d10617"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/awslabs/fast-differential-privacy\n","  Cloning https://github.com/awslabs/fast-differential-privacy to /tmp/pip-req-build-92wswmtq\n","  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy /tmp/pip-req-build-92wswmtq\n","  Resolved https://github.com/awslabs/fast-differential-privacy to commit 1202baa441c38c338415bc24e4cf12514c46bac0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastDP\n","  Building wheel for fastDP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastDP: filename=fastDP-1.1.0-py3-none-any.whl size=101664 sha256=78a7d9e28a7ce972c82088ffe03f522f5d7ffedff949ef01aa07213f58f0ef6b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ky54q31j/wheels/b3/2b/b5/62668a08336b29e28ca790358738474aa8c2c68359b494f454\n","Successfully built fastDP\n","Installing collected packages: fastDP\n","Successfully installed fastDP-1.1.0\n"]}],"source":["%pip install git+https://github.com/awslabs/fast-differential-privacy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15305,"status":"ok","timestamp":1701802891964,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"},"user_tz":300},"id":"nt1HGG1z-9-y","outputId":"18b57248-40d7-4537-f02d-62cb5deeff08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/Othercomputers/My Mac/CLIPcifar10/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeQ-nTlrp3NJ","executionInfo":{"status":"ok","timestamp":1701802892308,"user_tz":300,"elapsed":346,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"0a59d963-52a7-4397-b6bd-699b0e4ab7ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Mac/CLIPcifar10\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oFfio93KO12","outputId":"c829b06d-967a-47ef-c927-c662044f71b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Number of trainable components:  55 ; Number of trainable layers:  54\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","['_model.bn1.weight', '_model.bn1.bias', '_model.layer1.0.bn1.weight', '_model.layer1.0.bn1.bias', '_model.layer1.0.bn2.weight', '_model.layer1.0.bn2.bias', '_model.layer1.0.bn3.weight', '_model.layer1.0.bn3.bias', '_model.layer1.0.downsample.1.weight', '_model.layer1.0.downsample.1.bias', '_model.layer1.1.bn1.weight', '_model.layer1.1.bn1.bias', '_model.layer1.1.bn2.weight', '_model.layer1.1.bn2.bias', '_model.layer1.1.bn3.weight', '_model.layer1.1.bn3.bias', '_model.layer1.2.bn1.weight', '_model.layer1.2.bn1.bias', '_model.layer1.2.bn2.weight', '_model.layer1.2.bn2.bias', '_model.layer1.2.bn3.weight', '_model.layer1.2.bn3.bias', '_model.layer2.0.bn1.weight', '_model.layer2.0.bn1.bias', '_model.layer2.0.bn2.weight', '_model.layer2.0.bn2.bias', '_model.layer2.0.bn3.weight', '_model.layer2.0.bn3.bias', '_model.layer2.0.downsample.1.weight', '_model.layer2.0.downsample.1.bias', '_model.layer2.1.bn1.weight', '_model.layer2.1.bn1.bias', '_model.layer2.1.bn2.weight', '_model.layer2.1.bn2.bias', '_model.layer2.1.bn3.weight', '_model.layer2.1.bn3.bias', '_model.layer2.2.bn1.weight', '_model.layer2.2.bn1.bias', '_model.layer2.2.bn2.weight', '_model.layer2.2.bn2.bias', '_model.layer2.2.bn3.weight', '_model.layer2.2.bn3.bias', '_model.layer2.3.bn1.weight', '_model.layer2.3.bn1.bias', '_model.layer2.3.bn2.weight', '_model.layer2.3.bn2.bias', '_model.layer2.3.bn3.weight', '_model.layer2.3.bn3.bias', '_model.layer3.0.bn1.weight', '_model.layer3.0.bn1.bias', '_model.layer3.0.bn2.weight', '_model.layer3.0.bn2.bias', '_model.layer3.0.bn3.weight', '_model.layer3.0.bn3.bias', '_model.layer3.0.downsample.1.weight', '_model.layer3.0.downsample.1.bias', '_model.layer3.1.bn1.weight', '_model.layer3.1.bn1.bias', '_model.layer3.1.bn2.weight', '_model.layer3.1.bn2.bias', '_model.layer3.1.bn3.weight', '_model.layer3.1.bn3.bias', '_model.layer3.2.bn1.weight', '_model.layer3.2.bn1.bias', '_model.layer3.2.bn2.weight', '_model.layer3.2.bn2.bias', '_model.layer3.2.bn3.weight', '_model.layer3.2.bn3.bias', '_model.layer3.3.bn1.weight', '_model.layer3.3.bn1.bias', '_model.layer3.3.bn2.weight', '_model.layer3.3.bn2.bias', '_model.layer3.3.bn3.weight', '_model.layer3.3.bn3.bias', '_model.layer3.4.bn1.weight', '_model.layer3.4.bn1.bias', '_model.layer3.4.bn2.weight', '_model.layer3.4.bn2.bias', '_model.layer3.4.bn3.weight', '_model.layer3.4.bn3.bias', '_model.layer3.5.bn1.weight', '_model.layer3.5.bn1.bias', '_model.layer3.5.bn2.weight', '_model.layer3.5.bn2.bias', '_model.layer3.5.bn3.weight', '_model.layer3.5.bn3.bias', '_model.layer4.0.bn1.weight', '_model.layer4.0.bn1.bias', '_model.layer4.0.bn2.weight', '_model.layer4.0.bn2.bias', '_model.layer4.0.bn3.weight', '_model.layer4.0.bn3.bias', '_model.layer4.0.downsample.1.weight', '_model.layer4.0.downsample.1.bias', '_model.layer4.1.bn1.weight', '_model.layer4.1.bn1.bias', '_model.layer4.1.bn2.weight', '_model.layer4.1.bn2.bias', '_model.layer4.1.bn3.weight', '_model.layer4.1.bn3.bias', '_model.layer4.2.bn1.weight', '_model.layer4.2.bn1.bias', '_model.layer4.2.bn2.weight', '_model.layer4.2.bn2.bias', '_model.layer4.2.bn3.weight', '_model.layer4.2.bn3.bias'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n","Accuracy of the network on the 10000 test images: 18 %, time spent per epoch 904.7956931591034\n","Accuracy of the network on the 10000 test images: 18 %, time spent per epoch 900.2597658634186\n"]}],"source":["!python finetuning.py --name fttrial --seed 0 --epoch 40 --epsilon 1 --b 100 --lr 0.01"]},{"cell_type":"markdown","source":["### s0e50eps1.5b100lr0.001 Adam result\n","\n","10 %\n",",10 %\n",",10 %\n",",10 %\n",",10 %\n",",9 %\n",",11 %\n",",9 %\n","\n","### s0e50eps1.5b100lr0.001 SGD result\n","\n","9 %\n",",10 %\n",",10 %\n",",11 %\n",",12 %\n",",13 %\n",",15 %\n",",17 %\n","\n","### s0e50eps1.5b100lr0.01 SGD result\n","\n","15 %\n",",27 %\n",",36 %\n",",38 %\n",",37 %\n",",36 %\n",",35 %\n",",34 %\n",",34 %\n",",34 %\n",",34 %\n",",33 %\n","\n","### s0e20eps1b100lr0.1 SGD result\n","\n","10 %,10 %,10 %,10 %,10 %"],"metadata":{"id":"glSqn5O_Jdc1"}}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNV9oQ8WKyyiggJEjDbuZWo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}