{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyM1JrRimJDJ6WNeOqCQeJkL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtMgYty2eu2l","executionInfo":{"status":"ok","timestamp":1701941591487,"user_tz":300,"elapsed":14113,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"969b9c23-e52a-4a09-c060-d0c93ec02df7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/awslabs/fast-differential-privacy\n","  Cloning https://github.com/awslabs/fast-differential-privacy to /tmp/pip-req-build-9sh5_khj\n","  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy /tmp/pip-req-build-9sh5_khj\n","  Resolved https://github.com/awslabs/fast-differential-privacy to commit 053a82df69e48698053570e90bc24cd8bba26daf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastDP\n","  Building wheel for fastDP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastDP: filename=fastDP-1.1.0-py3-none-any.whl size=101667 sha256=22502fe2ba8400bf870f6e7c02e80a943413effd268ff09d1651f72896d12f0d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-pp65kob3/wheels/b3/2b/b5/62668a08336b29e28ca790358738474aa8c2c68359b494f454\n","Successfully built fastDP\n","Installing collected packages: fastDP\n","Successfully installed fastDP-1.1.0\n","Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu118)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: torchinfo, opacus\n","Successfully installed opacus-1.4.0 torchinfo-1.8.0\n"]}],"source":["%pip install git+https://github.com/awslabs/fast-differential-privacy\n","%pip install opacus torchinfo"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"s4rxv_cQfKGs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701941605346,"user_tz":300,"elapsed":13861,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"6e2abdaf-19be-400b-c2d1-574c033e0698"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/Othercomputers/My Mac/MOCOcifar10/"],"metadata":{"id":"TC4H4xoHfLR0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701941605347,"user_tz":300,"elapsed":8,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"9b13a30f-9bc8-452b-920e-5c839741e176"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Mac/MOCOcifar10\n"]}]},{"cell_type":"code","source":["!python main.py --seed 0 --epoch 30 --lp-epoch 0 --lplr 0 --ftlr 0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0w8ceS0YlGIv","outputId":"881ee3f0-a2b7-4d1b-a914-338ffc791320"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Total parameters 23528522. Trainable parameters 20490.\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","Number of trainable components:  161 ; Number of trainable layers:  107\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]}]},{"cell_type":"code","source":["!python main.py --seed 0 --epoch 30 --lp-epoch 0 --lplr 0 --ftlr 0.05"],"metadata":{"id":"5kaF-zWJk6c8"},"execution_count":null,"outputs":[]}]}