{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMrR40OAzyPIctPyFSoxZUV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DtMgYty2eu2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701941708191,"user_tz":300,"elapsed":12708,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"2a400bec-4a42-47a6-c670-790369af192b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/awslabs/fast-differential-privacy\n","  Cloning https://github.com/awslabs/fast-differential-privacy to /tmp/pip-req-build-2d5ldgo1\n","  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy /tmp/pip-req-build-2d5ldgo1\n","  Resolved https://github.com/awslabs/fast-differential-privacy to commit 053a82df69e48698053570e90bc24cd8bba26daf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fastDP\n","  Building wheel for fastDP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastDP: filename=fastDP-1.1.0-py3-none-any.whl size=101667 sha256=ee673d1a0999fc3eae661e140d04020a940227ddc2dfe6a3aadd7dcf8f254cc8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kl7wi5b9/wheels/b3/2b/b5/62668a08336b29e28ca790358738474aa8c2c68359b494f454\n","Successfully built fastDP\n","Installing collected packages: fastDP\n","Successfully installed fastDP-1.1.0\n","Collecting opacus\n","  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.1.0+cu118)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.11.4)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n","Installing collected packages: torchinfo, opacus\n","Successfully installed opacus-1.4.0 torchinfo-1.8.0\n"]}],"source":["%pip install git+https://github.com/awslabs/fast-differential-privacy\n","%pip install opacus torchinfo"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"s4rxv_cQfKGs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701941720232,"user_tz":300,"elapsed":12043,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"8d5393bf-be95-4bbe-f67a-b364dc5b28df"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/Othercomputers/My Mac/MOCOcifar10/"],"metadata":{"id":"TC4H4xoHfLR0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701941720232,"user_tz":300,"elapsed":5,"user":{"displayName":"jingtian ke","userId":"11426208050859465028"}},"outputId":"b907b288-838c-48c6-bddb-f04a103b0d20"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Mac/MOCOcifar10\n"]}]},{"cell_type":"code","source":["!python main.py --device cuda:0 --seed 0 --epoch 30 --lp-epoch 0 --lplr 0 --ftlr 0.01"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBf_zveolAmk","outputId":"cf5d89de-6291-4029-8755-cb2e42abc09b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Total parameters 23528522. Trainable parameters 20490.\n","Number of trainable components:  2 ; Number of trainable layers:  1\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.fc']\n","Number of trainable components:  161 ; Number of trainable layers:  107\n",">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['_model.conv1']\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n","10.0 362.1860888004303\n"]}]},{"cell_type":"code","source":["!python main.py --seed 0 --epoch 30 --lp-epoch 0 --lplr 0 --ftlr 0.005"],"metadata":{"id":"UvGwC67zo3n4"},"execution_count":null,"outputs":[]}]}